PATH = "C:\Web_Scraping\chromedriver.exe" #webdriver path
xlpath = "C:\Web_Scraping\BOM.xlsx" #excel file path
url_col = 3
data1_col = 4
data2_col = 5
url_start = 2
url_end = 4

xpath1 = "/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div[4]/div[1]/div/div[1]" #full xpath of data 0
xpath2 = "/html/body/div[1]/div/div[3]/div[1]/div[2]/div[2]/div/div[4]/div[1]/div/div[1]" #full xpath of data 1

from openpyxl import load_workbook
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

file =load_workbook(xlpath)
sheet = file.active

browser = webdriver.Chrome(PATH)

def web_scrape(url):

    browser.get(url)
    try:
        stock = WebDriverWait(browser, 50).until(
            EC.presence_of_element_located((By.XPATH, xpath1))
        )

        unitcost = WebDriverWait(browser, 50).until(
            EC.presence_of_element_located((By.XPATH, xpath2))
        )
        #return [stock.text[:-9],unitcost.text[2:]]
        return [stock.text,unitcost.text]

    finally:
        #browser.quit()
        print("paused")
        time.sleep(1)
        
for i in range(url_start,(url_end+1)):
    web_scrape_out = web_scrape(sheet.cell(row=i,column=url_col).value)
    print(web_scrape_out[0]+"   "+web_scrape_out[1])
    sheet.cell(row=i,column=data1_col).value = web_scrape_out[0]
    sheet.cell(row=i,column=data2_col).value = web_scrape_out[1]
    print("ok")

file.save("C:\Web_Scraping\BOM.xlsx")
browser.close()
